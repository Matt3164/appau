{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd554d28",
   "metadata": {},
   "source": [
    "# Hyperopt\n",
    "\n",
    "Librairie gérant la recherche d'hyper paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3535133a",
   "metadata": {},
   "source": [
    "# How to hyperparameter tuning using hyperopt\n",
    "\n",
    "[Source](https://docs.azuredatabricks.net/_static/notebooks/hyperopt-sklearn-model-selection.html).\n",
    "\n",
    "Please check [Hyperparatemer tuning](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)) for more details on the basic principles.\n",
    "\n",
    "`hyperopt` is one of the many open source libraries available to do it in Python. Here is an example on how to use it to optimize the type classifier and its parameters at the end of sklearn pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f31feee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  2.37trial/s, best loss: -0.897]\n",
      "{'classifier': 0, 'n_neighbors': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, KBinsDiscretizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from hyperopt import tpe, hp, fmin, STATUS_OK\n",
    "\n",
    "x, y = make_classification(1000)\n",
    "\n",
    "def objective(params):\n",
    "    global x, y\n",
    "    pipe = make_pipeline(\n",
    "        ColumnTransformer(\n",
    "            [\n",
    "                (\"scaled\", StandardScaler(), slice(0, 10)),\n",
    "                (\"disc\", KBinsDiscretizer(n_bins=10), slice(10,12)),\n",
    "                (\"rest\", \"passthrough\", slice(12,20))\n",
    "        ]), \n",
    "        PCA(n_components=2),\n",
    "        params[\"model\"](**params[\"kwargs\"])\n",
    "    )\n",
    "    \n",
    "    pipe.fit(x, y)\n",
    "\n",
    "    accuracy =accuracy_score(pipe.predict(x), y)\n",
    "    \n",
    "    return {'loss': -accuracy, \"status\": STATUS_OK}\n",
    "\n",
    "search_space = hp.choice(\"classifier\",[\n",
    "        {'model': KNeighborsClassifier,\n",
    "        'kwargs': {'n_neighbors': hp.choice('n_neighbors',range(3,11))}\n",
    "        },\n",
    "        {'model': MLPClassifier,\n",
    "        'kwargs': {'hidden_layer_sizes':hp.choice('layers',[(10,10), (100,100), (256,256)])}}\n",
    "        ])\n",
    "\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=objective, \n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=4,\n",
    "    )\n",
    "print(best_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
